{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project we going to explore, process & store three datasets:\n",
    "   * Bitcoin-USD \n",
    "   * cities demographics\n",
    "   * Immigration data\n",
    "The first two datasets are in CSV and third in SAS file format.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and  here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction as udf\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import datetime \n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project we gonna load three datasets and explore them, then fix and clean if needed, finally, we load them into tables and check on quality.\n",
    "using tools: Pandas, spark as data store.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "I'm going to load and explore three datasets of:\n",
    "   1. Bitcoin-USD data from sep-2014 till march-2022\n",
    "   2. us cities demographics\n",
    "   3. immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2014-09-17  465.864014  468.174011  452.421997  457.334015  457.334015   \n",
       "1  2014-09-18  456.859985  456.859985  413.104004  424.440002  424.440002   \n",
       "2  2014-09-19  424.102997  427.834991  384.532013  394.795990  394.795990   \n",
       "3  2014-09-20  394.673004  423.295990  389.882996  408.903992  408.903992   \n",
       "4  2014-09-21  408.084991  412.425995  393.181000  398.821014  398.821014   \n",
       "\n",
       "     Volume  \n",
       "0  21056800  \n",
       "1  34483200  \n",
       "2  37919700  \n",
       "3  36863600  \n",
       "4  26580100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in \"Bitcoin-USD\" data\n",
    "bitcoin_df = pd.read_csv(\"BTC-USD.csv\")\n",
    "bitcoin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2.747000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11668.600272</td>\n",
       "      <td>11981.034949</td>\n",
       "      <td>11325.596907</td>\n",
       "      <td>11682.892098</td>\n",
       "      <td>11682.892098</td>\n",
       "      <td>1.484704e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16323.683853</td>\n",
       "      <td>16759.568657</td>\n",
       "      <td>15825.584507</td>\n",
       "      <td>16330.191582</td>\n",
       "      <td>16330.191582</td>\n",
       "      <td>1.994819e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>176.897003</td>\n",
       "      <td>211.731003</td>\n",
       "      <td>171.509995</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>178.102997</td>\n",
       "      <td>5.914570e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>609.122009</td>\n",
       "      <td>611.894501</td>\n",
       "      <td>606.309478</td>\n",
       "      <td>609.234009</td>\n",
       "      <td>609.234009</td>\n",
       "      <td>8.161285e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6371.850098</td>\n",
       "      <td>6500.870117</td>\n",
       "      <td>6285.629883</td>\n",
       "      <td>6376.709961</td>\n",
       "      <td>6376.709961</td>\n",
       "      <td>5.227550e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10728.271485</td>\n",
       "      <td>10992.468751</td>\n",
       "      <td>10412.890137</td>\n",
       "      <td>10755.395019</td>\n",
       "      <td>10755.395019</td>\n",
       "      <td>2.500517e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67549.734375</td>\n",
       "      <td>68789.625000</td>\n",
       "      <td>66382.062500</td>\n",
       "      <td>67566.828125</td>\n",
       "      <td>67566.828125</td>\n",
       "      <td>3.509679e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close     Adj Close  \\\n",
       "count   2747.000000   2747.000000   2747.000000   2747.000000   2747.000000   \n",
       "mean   11668.600272  11981.034949  11325.596907  11682.892098  11682.892098   \n",
       "std    16323.683853  16759.568657  15825.584507  16330.191582  16330.191582   \n",
       "min      176.897003    211.731003    171.509995    178.102997    178.102997   \n",
       "25%      609.122009    611.894501    606.309478    609.234009    609.234009   \n",
       "50%     6371.850098   6500.870117   6285.629883   6376.709961   6376.709961   \n",
       "75%    10728.271485  10992.468751  10412.890137  10755.395019  10755.395019   \n",
       "max    67549.734375  68789.625000  66382.062500  67566.828125  67566.828125   \n",
       "\n",
       "             Volume  \n",
       "count  2.747000e+03  \n",
       "mean   1.484704e+10  \n",
       "std    1.994819e+10  \n",
       "min    5.914570e+06  \n",
       "25%    8.161285e+07  \n",
       "50%    5.227550e+09  \n",
       "75%    2.500517e+10  \n",
       "max    3.509679e+11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_pop</th>\n",
       "      <th>female_pop</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>num_vetarans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  median_age  male_pop  female_pop  \\\n",
       "0     Silver Spring       Maryland        33.8   40601.0     41862.0   \n",
       "1            Quincy  Massachusetts        41.0   44129.0     49500.0   \n",
       "2            Hoover        Alabama        38.5   38040.0     46799.0   \n",
       "3  Rancho Cucamonga     California        34.5   88127.0     87105.0   \n",
       "4            Newark     New Jersey        34.6  138040.0    143873.0   \n",
       "\n",
       "   total_pop  num_vetarans  foreign_born  avg_household_size state_code  \\\n",
       "0      82463        1562.0       30908.0                2.60         MD   \n",
       "1      93629        4147.0       32935.0                2.39         MA   \n",
       "2      84839        4819.0        8229.0                2.58         AL   \n",
       "3     175232        5821.0       33878.0                3.18         CA   \n",
       "4     281913        5829.0       86253.0                2.73         NJ   \n",
       "\n",
       "                        race  count  \n",
       "0         Hispanic or Latino  25924  \n",
       "1                      White  58723  \n",
       "2                      Asian   4759  \n",
       "3  Black or African-American  24437  \n",
       "4                      White  76402  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in \"US cities demographics\" data here\n",
    "demography_df = pd.read_csv(\"us-cities-demographics.csv\", sep=';')\n",
    "demography_df.columns = ['city', 'state', 'median_age', 'male_pop', 'female_pop', 'total_pop', 'num_vetarans', 'foreign_born', 'avg_household_size', 'state_code', 'race', 'count']\n",
    "demography_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loading full immigration data\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-------+-------+-------+-------+-------+-------+\n",
      "|cicid| i94yr|i94mon|i94port|i94addr|arrdate|depdate|i94mode|i94visa|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+-------+\n",
      "|  6.0|2016.0|   4.0|    XXX|   null|20573.0|   null|   null|    2.0|\n",
      "|  7.0|2016.0|   4.0|    ATL|     AL|20551.0|   null|    1.0|    3.0|\n",
      "| 15.0|2016.0|   4.0|    WAS|     MI|20545.0|20691.0|    1.0|    2.0|\n",
      "| 16.0|2016.0|   4.0|    NYC|     MA|20545.0|20567.0|    1.0|    2.0|\n",
      "| 17.0|2016.0|   4.0|    NYC|     MA|20545.0|20567.0|    1.0|    2.0|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting needed columns only\n",
    "immigration_df = df_spark[['cicid', 'i94yr', 'i94mon', 'i94port', 'i94addr', 'arrdate', 'depdate', 'i94mode', 'i94visa']]\n",
    "immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "    1. Transform all columns titles to lowercase and depricate 'Adj Close' column then converting to Spark dataframe\n",
    "    2. Fixing data types for demography dataset then converting to Spark dataframe\n",
    "    3. Rename columns in immigration dataset.\n",
    "    \n",
    "##### 1. Transform all columns titles to lowercase and depricate 'Adj Close' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume\n",
       "0  2014-09-17  465.864014  468.174011  452.421997  457.334015  21056800\n",
       "1  2014-09-18  456.859985  456.859985  413.104004  424.440002  34483200\n",
       "2  2014-09-19  424.102997  427.834991  384.532013  394.795990  37919700\n",
       "3  2014-09-20  394.673004  423.295990  389.882996  408.903992  36863600\n",
       "4  2014-09-21  408.084991  412.425995  393.181000  398.821014  26580100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanBitcoin(df):\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df['date'] =  pd.to_datetime(df['date']).astype('datetime64').dt.strftime(\"%Y-%m-%d\")\n",
    "    df['volume'] =  df['volume'].values.astype(int)\n",
    "    return df\n",
    "\n",
    "bitcoin_df = cleanBitcoin(bitcoin_df)\n",
    "sparkDF = spark.createDataFrame(bitcoin_df)\n",
    "sparkDF.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Fixing data types for demography dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+--------+----------+---------+------------+------------+------------------+----------+------------------+-----+\n",
      "|         city|        state|median_age|male_pop|female_pop|total_pop|num_vetarans|foreign_born|avg_household_size|state_code|              race|count|\n",
      "+-------------+-------------+----------+--------+----------+---------+------------+------------+------------------+----------+------------------+-----+\n",
      "|Silver Spring|     Maryland|      33.8|   40601|   41862.0|    82463|      1562.0|     30908.0|               2.6|        MD|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|      41.0|   44129|   49500.0|    93629|      4147.0|     32935.0|              2.39|        MA|             White|58723|\n",
      "+-------------+-------------+----------+--------+----------+---------+------------+------------+------------------+----------+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cleanDemography(df):\n",
    "    df = df.dropna()\n",
    "    df['male_pop'] = df['male_pop'].astype('int')\n",
    "    return df\n",
    "\n",
    "demography_df = cleanDemography(demography_df)\n",
    "sparkDF2 = spark.createDataFrame(demography_df)\n",
    "sparkDF2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3. Immigration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+---------+----------+-----------+--------------+----+----+\n",
      "|cic_id|  year|month|city_code|state_code|arrive_date|departure_date|mode|visa|\n",
      "+------+------+-----+---------+----------+-----------+--------------+----+----+\n",
      "|   6.0|2016.0|  4.0|      XXX|      null|    20573.0|          null|null| 2.0|\n",
      "|   7.0|2016.0|  4.0|      ATL|        AL|    20551.0|          null| 1.0| 3.0|\n",
      "+------+------+-----+---------+----------+-----------+--------------+----+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cleanImmigration(df):\n",
    "    oldcolumns = ['cicid', 'i94yr', 'i94mon', 'i94port', 'i94addr', 'arrdate', 'depdate', 'i94mode', 'i94visa']\n",
    "    newcolumns = ['cic_id', 'year', 'month', 'city_code', 'state_code', 'arrive_date', 'departure_date', 'mode', 'visa']\n",
    "    for item in range(0, len(oldcolumns)):\n",
    "        df = df.withColumnRenamed(oldcolumns[item],newcolumns[item])\n",
    "    return df\n",
    "\n",
    "immigration_df = cleanImmigration(immigration_df)\n",
    "immigration_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "###### The model is immigration data as fact table with demography as a related dimension table. The bitcoin data is not so related but we can attach them all with Date as a forign key.\n",
    "\n",
    "\n",
    "| Table        | columns                                                                                                                                                                | description                         | type            |\n",
    "|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------|-----------------|\n",
    "| bitcoin      | Date - Open - High - Low - Close - Volume                                                                                                                              | stores bitcoin price data           | dimension table |\n",
    "| demography   | city - state - media_age - male_population - female_population -  total_population - num_veterans - foreign_born - average_household_size -  state_code - race - count | stores demographics data for cities | dimension table |\n",
    "| immigrations | cicid - year - month - city - arrdate - mode - depdate - visa - count                                                                                                  | stores immigrations data            | fact table      |\n",
    "\n",
    "##### The data dictionaries as below:\n",
    "\n",
    "|date|open|high|low|close|volume|\n",
    "|----|----|----|---|-----|------|\n",
    "|the date of record |open price |highest price of day |lowest price |close price |volume of trading |\n",
    "\n",
    "|city|state|median_age|male_pop|female_pop|total_pop|num_vetarans|foreign_born|avg_household_size|state_code|race|count|\n",
    "|----|------|----------|--------|---------|-----------|----------|------------|-----------------|----------|-----|------|\n",
    "|the city name |state nameian age | male population | female pop | tolal pop | number of vetarnas | foreign born | average household size | state code | race | count\n",
    "\n",
    "|cic_id|year|month|city_code|state_code|arrive_date|departure_date|mode|visa|\n",
    "|------|----|-----|---------|----------|-----------|--------------|----|---|\n",
    "|cic id number | year | month | city code | state code |arrive date |departure date |mode | visa type|\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "    1. Assume all data sets are stored in same dir.\n",
    "    2. Cleaning up datasets\n",
    "    3. writing then into spark parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing three datasets into spark parquet\n",
    "sparkDF.write.mode('overwrite').parquet(\"datasets_sas/bitcoin\")\n",
    "sparkDF2.write.mode('overwrite').parquet(\"datasets_sas/demography\")\n",
    "immigration_df.write.mode('overwrite').parquet(\"datasets_sas/immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demography is not empty: with total 2875 records.\n",
      "bitcoin is not empty: with total 2747 records.\n",
      "immigration is not empty: with total 3096313 records.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "sasfiles = Path('datasets_sas/')\n",
    "\n",
    "# Checks for empty records\n",
    "for file_dir in sasfiles.iterdir():\n",
    "    if file_dir.is_dir():\n",
    "        path = str(file_dir)\n",
    "        df = spark.read.parquet(path)\n",
    "        record_num = df.count()\n",
    "        if record_num <= 0:\n",
    "            raise ValueError(\"This table is empty!\")\n",
    "        else:\n",
    "            print(path.split('/')[-1] + f\" is not empty: with total {record_num} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+--------+----------+---------+------------+------------+------------------+----------+----+-----+\n",
      "|city|state|median_age|male_pop|female_pop|total_pop|num_vetarans|foreign_born|avg_household_size|state_code|race|count|\n",
      "+----+-----+----------+--------+----------+---------+------------+------------+------------------+----------+----+-----+\n",
      "|   0|    0|         0|       0|         0|        0|           0|           0|                 0|         0|   0|    0|\n",
      "+----+-----+----------+--------+----------+---------+------------+------------+------------------+----------+----+-----+\n",
      "\n",
      "demography has = None records of Nan Values.\n",
      "\n",
      "+----+----+----+---+-----+------+\n",
      "|date|open|high|low|close|volume|\n",
      "+----+----+----+---+-----+------+\n",
      "|   0|   0|   0|  0|    0|     0|\n",
      "+----+----+----+---+-----+------+\n",
      "\n",
      "bitcoin has = None records of Nan Values.\n",
      "\n",
      "+------+----+-----+---------+----------+-----------+--------------+----+----+\n",
      "|cic_id|year|month|city_code|state_code|arrive_date|departure_date|mode|visa|\n",
      "+------+----+-----+---------+----------+-----------+--------------+----+----+\n",
      "|     0|   0|    0|        0|         0|          0|             0|   0|   0|\n",
      "+------+----+-----+---------+----------+-----------+--------------+----+----+\n",
      "\n",
      "immigration has = None records of Nan Values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checks for Nan values count\n",
    "for file_dir in sasfiles.iterdir():\n",
    "    if file_dir.is_dir():\n",
    "        path = str(file_dir)\n",
    "        df = spark.read.parquet(path)\n",
    "        record_num = df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()\n",
    "        print(path.split('/')[-1] + f\" has {record_num} records of Nan Values.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* For this project I've selected jupyter as a visualisation & processing tool and Spark as data store.\n",
    "* The datasets should be updated monthly, as immigration dataset updated in that interval. \n",
    "* If the data increased a hundred times we should use a NoSQL database, and distributed data storage like S3.\n",
    "* For a 100 users, AWS Redshift allows a max of 500 connections and 50 concurrencies per cluster.\n",
    "* For scheduled pipelines a tool like Airflow can be used. It has the advantage, that it provides a web view, so that also non programmers can check wether a pipeline ran successfully or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
